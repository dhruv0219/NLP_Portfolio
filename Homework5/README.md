**HOW TO RUN THE PROGRAM

The first step before running the program is to import and download nltk and many of the packages that are installed within it. Along with this make sure that
beautiful soup 4 is installed. Once all the requirements and installations are made, then run the program by typing the command **python3 Homework5_Dxt180017.py**.
From there the program will take some time to run but the knowledge base will be created as a pickle file.

**LESSONS LEARNED

This assignment was an interesting assignment to do as I had prior experience with web crawling, however I did not have experience with crawling the web and then
turning that information into a knowledge base for future use. It required me to think with a different perspective as it was now important to get information from websites
that can be tokenized easily into an accessible knowledge base. Along with this it was somewhat difficult as certain websites did not allow for webscraping so much of the time
was spent trying to figure out what a good starting page was, which could then direct us to other links that may help build out the knowledge base. Ofentimes websites
would have empty information which made it difficult to get the required information. Once the text was identified it was much easier to then tokenize the data and turn it into
a knowledge base.
